1-1
- Where is the origin placed in the on-screen coordinate system?

Middle of the screen. 0.0, 0.0, 0.0.
-----
- Which direction are the X and Y axes pointing in the on-screen coordinate system?

X moves to the right.
Y moves to the top.
-----
- The triangle color is controlled from the fragment shader. Would it be possible to control it form the main program? How?

Maybe by getting a pointer to the triangle and changing color off it.
---------------


1-2
- What is the purpose of the "in", "out" and "uniform" modifiers?

"in" and "out" are used for the pipeline to specify the vertices that the gpu is working with. "uniform" is used for user defined matrices that are to transform, rotate etc the vertices.
"in" comes from previous stages and "out" goes to the next stage in the pipeline.
-----
- What is the output of the vertex shader?

A rotated, transformed (etc) object as a matrix.
-----
- What does the function glUniformMatrix4fv do?

It sets the variables in the .vert file so it can use the matrix multiplactions. It also transforms a GLfloat vector into a matrix.
---------------


1-3
What is the purpose of glutPostRedisplay()?
What is the frame rate of the animation?

frame updates every 20 ms => 50 fps

Did you get a noticable flicker? Did the double buffering help?
---------------


1-4
Did you need to do anything different when uploading the color data?
The "in" and "out" modifiers are now used for something different. What?
What is this kind of shading called? What could we use otherwise?
---------------


1-5
What problems did you encounter while building the cube?
How do you change the facing of a polygon?
---------------


1-6
Why do we need normal vectors for a model?
What did you do in your fragment shader?
Should a normal vector always be perpendicular to a certain triangle? If not, why?
Now we are using glBindBuffer and glBufferData again. They deal with buffers, but in what way?
---------------


1-7
Did you implement your light calculations in the vertex or fragment shader? So, which kind of shading did you implement?
Some geometry data must be vec4, others are just as well vec3's. Which ones, and why? How about vertices, light source, normal vectors...?
---------------


1-8
Was the difference big? If not, why?
You are doing almost the same operations. So what is the difference performance-wise? Compare the two methods from a performance standpoint.