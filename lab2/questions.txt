2-1
- How are the textures coordinates mapped on the bunny? Can you see what geometry was used?
.s -> mapped to left, .t -> mapped upwards...... isch... 
We used 
	outColor = vec4(1.0,texCoord.t,1.0,0.0);
in the fragment shader and got a rabbit with a purple gradient.

- What kind of procedural texture did you make?
A psycadelic rabbit! =) (From the slides)




2-2
- Can we modify how we access the texture? How?
With the texture - function.

- Why can't we just pass the texture object to the shader? There is a specific reason for this, a limited resource. What?
Graphic memory problem when using a lot of textures.



2-3
- How did you move the bunny to get it in view?
We placed it Z = -2



2-4
- Given a certain vector for v, is there some place you can't place the camera?




2-5
- Did you implement your light calculations in the vertex or fragment shader? So, which kind of shading did you implement?
Some geometry data must be vec4, others are just as well vec3's. Which ones, and why? How about vertices, light source, normal vectors...?




2-6
- Was the difference big? If not, why?
- You are doing almost the same operations. So what is the difference performance-wise? Compare the two methods from a performance standpoint.




2-7
If you rotate an object or rotate the camera, what matrices are affected?